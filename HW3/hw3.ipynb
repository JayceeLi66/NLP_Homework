{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xAYEa3BCZL3w",
        "sxrE8uxMaIue"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgW-26Kl9j8m",
        "colab_type": "text"
      },
      "source": [
        "---   \n",
        "# HW3 - Transfer learning\n",
        "\n",
        "#### Due October 30, 2019\n",
        "\n",
        "In this assignment you will learn about transfer learning. This technique is perhaps one of the most important techniques for industry. When a problem you want to solve does not have enough data, we use a different (larger) dataset to learn representations which can help us solve our task using the smaller task.\n",
        "\n",
        "The general steps to transfer learning are as follows:\n",
        "\n",
        "1. Find a huge dataset with similar characteristics to the problem you are interested in.\n",
        "2. Choose a model powerful enough to extract meaningful representations from the huge dataset.\n",
        "3. Train this model on the huge dataset.\n",
        "4. Use this model to train on the smaller dataset.\n",
        "\n",
        "\n",
        "### This homework has the following sections:\n",
        "1. Question 1: MNIST fine-tuning (Parts A, B, C, D).\n",
        "2. Question 2: Pretrain on Wikitext2 (Part A, B, C, D)\n",
        "3. Question 3: Finetune on MNLI (Part A, B, C, D)\n",
        "4. Question 4: Finetune using pretrained BERT (Part A, B, C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtuJJ18j9j8n",
        "colab_type": "text"
      },
      "source": [
        "---   \n",
        "## Question 1 (MNIST transfer learning)\n",
        "To grasp the high-level approach to transfer learning, let's first do a simple example using computer vision. \n",
        "\n",
        "The torchvision library has pretrained models (resnets, vggnets, etc) on the Imagenet dataset. Imagenet is a dataset\n",
        "with 1.3 million images covering over 1000 classes of objects. When you use one of these models, the weights of the model initialize\n",
        "with the weights saved from training on imagenet.\n",
        "\n",
        "In this task we will:\n",
        "1. Choose a pretrained model.\n",
        "2. Freeze the model so that the weights don't change.\n",
        "3. Fine-tune on a few labels of MNIST.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz6aWWu-9j8o",
        "colab_type": "text"
      },
      "source": [
        "#### Choose a model\n",
        "Here we pick any of the models from torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4kCA7-I9j8p",
        "colab_type": "code",
        "outputId": "c7bd18cc-52b4-4684-e6b3-94bce3a19174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "class Identity(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "# init the pretrained feature extractor\n",
        "pretrained_resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "# we don't want the built in last layer, we're going to modify it ourselves\n",
        "pretrained_resnet18.fc = Identity()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 74.8MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO4aPAkr9j8t",
        "colab_type": "text"
      },
      "source": [
        "#### Freeze the model\n",
        "Here we freeze the weights of the model. Freezing means the gradients will not backpropagate\n",
        "into these weights.\n",
        "\n",
        "By doing this you can think about the model as a feature extractor. This feature extractor outputs\n",
        "a **representation** of an input. This representation is a matrix that encodes information about the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvc1m6M99j8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "        \n",
        "def unfreeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "        \n",
        "freeze_model(pretrained_resnet18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljmcEjwt9j8x",
        "colab_type": "text"
      },
      "source": [
        "#### Init target dataset\n",
        "Here we define the dataset we are actually interested in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pQ6sWKm9j8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import  MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "transform = transforms.Compose([transforms.Grayscale(3),\n",
        "transforms.ToTensor()\n",
        "])                          \n",
        "#  train/val  split\n",
        "mnist_dataset = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "mnist_train, mnist_val = random_split(mnist_dataset, [55000, 5000])\n",
        "\n",
        "mnist_train = DataLoader(mnist_train, batch_size=32)\n",
        "mnist_val = DataLoader(mnist_val,batch_size=32)\n",
        "\n",
        "# test split\n",
        "mnist_test = DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transform), batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNTEW7xB9j8z",
        "colab_type": "text"
      },
      "source": [
        "### Part A (init fine-tune model)\n",
        "decide what model to use for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYl1JFfC9j80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def init_fine_tune_model():\n",
        "  class fine_tune_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.s= nn.Sequential(nn.Linear(512,216), nn.ReLU(), nn.Dropout(0.4), nn.Linear(216, 10))   \n",
        "    def forward(self, data):\n",
        "        logits=self.s(data)\n",
        "        return logits\n",
        "  return fine_tune_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5hf0pdW9j82",
        "colab_type": "text"
      },
      "source": [
        "### Part B (Fine-tune (Frozen))\n",
        "\n",
        "The actual problem we care about solving likely has a different number of classes or is a different task altogether. Fine-tuning is the process of using the extracted representations (features) to solve this downstream task  (the task you're interested in).\n",
        "\n",
        "To illustrate this, we'll use our pretrained model (on Imagenet), to solve the MNIST classification task.\n",
        "\n",
        "There are two types of finetuning. \n",
        "\n",
        "#### 1. Frozen feature_extractor\n",
        "In the first type we pretrain with the FROZEN feature_extractor and NEVER unfreeze it during finetuning.\n",
        "\n",
        "\n",
        "#### 2. Unfrozen feature_extractor\n",
        "In the second, we finetune with a FROZEN feature_extractor for a few epochs, then unfreeze the feature extractor and finish training.\n",
        "\n",
        "\n",
        "In this part we will use the first version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U07X9lr9j82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def FROZEN_fine_tune_mnist(feature_extractor, fine_tune_model, mnist_train, mnist_val):\n",
        "    \"\"\"\n",
        "    model is a feature extractor (resnet).\n",
        "    Create a new model which uses those features to finetune on MNIST\n",
        "    \n",
        "    return the fine_tune model\n",
        "    \"\"\"     \n",
        "        \n",
        "    device = torch.device(\"cuda:0\")\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    fine_tune_model.to(device)\n",
        "    feature_extractor.to(device)\n",
        "    feature_extractor.fc = fine_tune_model\n",
        "    model = feature_extractor\n",
        "    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
        "    # Train!\n",
        "    for epoch_number in range(15):\n",
        "        model.train()\n",
        "        for inp, target in mnist_train:\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(device)\n",
        "            target = target.to(device)   \n",
        "            logits = model(inp)\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        model.eval()\n",
        "        total=0\n",
        "        correct=0\n",
        "        with torch.no_grad():\n",
        "            for inp, target in mnist_val:\n",
        "                inp = inp.to(device)\n",
        "                target = target.to(device)\n",
        "                logits = model(inp)\n",
        "\n",
        "                outputs = F.softmax(logits,dim=1)\n",
        "                predicted = outputs.max(1, keepdim=True)[1]\n",
        "                total += target.size(0)\n",
        "                correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
        "\n",
        "            print('Validation acc after '+str(epoch_number+1)+' epochs = {:.{prec}f}'.format((100 * correct / total), prec=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvHC9HfS9j84",
        "colab_type": "text"
      },
      "source": [
        "### Part C (compute test accuracy)\n",
        "Compute the test accuracy of fine-tuned model on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlXGT0nQ9j85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_mnist_test_accuracy(feature_extractor, fine_tune_model, mnist_test):\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    fine_tune_model.eval()\n",
        "    for inp, target in mnist_test:\n",
        "        inp = inp.to(device)\n",
        "        inp = feature_extractor(inp)\n",
        "        target = target.to(device)   \n",
        "        output = F.softmax(inp,dim=1)\n",
        "        pred = output.max(1,keepdim=True)[1]\n",
        "        total += target.size(0)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    \n",
        "    return 100*correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lcoDEJq9j87",
        "colab_type": "text"
      },
      "source": [
        "### Grade!\n",
        "Let's see how you did"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cldDtu1t9j87",
        "colab_type": "code",
        "outputId": "2afdb9b7-ec9f-4472-f0a3-7ce67954ae13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "def grade_mnist_frozen():\n",
        "    \n",
        "    # init a ft model\n",
        "    fine_tune_model = init_fine_tune_model()\n",
        "    \n",
        "    # run the transfer learning routine\n",
        "    FROZEN_fine_tune_mnist(pretrained_resnet18, fine_tune_model, mnist_train, mnist_val)\n",
        "    \n",
        "    # calculate test accuracy\n",
        "    test_accuracy = calculate_mnist_test_accuracy(pretrained_resnet18, fine_tune_model, mnist_test)\n",
        "    \n",
        "    # the real threshold will be released by Oct 11 \n",
        "    assert test_accuracy > 0.0, 'your accuracy is too low...'\n",
        "    \n",
        "    return test_accuracy\n",
        "    \n",
        "frozen_test_accuracy = grade_mnist_frozen()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation acc after 1 epochs = 60.7000\n",
            "Validation acc after 2 epochs = 67.0600\n",
            "Validation acc after 3 epochs = 69.7000\n",
            "Validation acc after 4 epochs = 71.6600\n",
            "Validation acc after 5 epochs = 73.1200\n",
            "Validation acc after 6 epochs = 73.9600\n",
            "Validation acc after 7 epochs = 74.2400\n",
            "Validation acc after 8 epochs = 74.6000\n",
            "Validation acc after 9 epochs = 74.7400\n",
            "Validation acc after 10 epochs = 75.0200\n",
            "Validation acc after 11 epochs = 75.2800\n",
            "Validation acc after 12 epochs = 75.5200\n",
            "Validation acc after 13 epochs = 75.8800\n",
            "Validation acc after 14 epochs = 76.1200\n",
            "Validation acc after 15 epochs = 76.3400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcBPftkkY__2",
        "colab_type": "code",
        "outputId": "108cfca0-831f-451a-d460-180f31b3a661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "frozen_test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeujuNyG9j89",
        "colab_type": "text"
      },
      "source": [
        "### Part D (Fine-tune Unfrozen)\n",
        "Now we'll learn how to train using the \"unfrozen\" approach.\n",
        "\n",
        "In this approach we'll:\n",
        "1. keep the feature_extract frozen for a few epochs (10)\n",
        "2. Unfreeze it.\n",
        "3. Finish training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-pp4DdS9j8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def UNFROZEN_fine_tune_mnist(feature_extractor, fine_tune_model, mnist_train, mnist_val):\n",
        "\n",
        "    # INSERT YOUR CODE:\n",
        "    # keep frozen for 10 epochs\n",
        "    # ... train\n",
        "    # unfreeze\n",
        "    # train for rest of the time\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    fine_tune_model.to(device)\n",
        "    feature_extractor.to(device)\n",
        "    feature_extractor.fc = fine_tune_model\n",
        "    model = feature_extractor\n",
        "    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
        "    # Train!\n",
        "    for epoch_number in range(15):\n",
        "        if epoch_number == 10:\n",
        "            unfreeze_model(model)\n",
        "            optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
        "        model.train()\n",
        "        for inp, target in mnist_train:\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(device)\n",
        "            target = target.to(device)   \n",
        "            logits = model(inp)\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        model.eval()\n",
        "        total=0\n",
        "        correct=0\n",
        "        with torch.no_grad():\n",
        "            for inp, target in mnist_val:\n",
        "                inp = inp.to(device)\n",
        "                target = target.to(device)\n",
        "                logits = model(inp)\n",
        "\n",
        "                outputs = F.softmax(logits,dim=1)\n",
        "                predicted = outputs.max(1, keepdim=True)[1]\n",
        "                total += target.size(0)\n",
        "                correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
        "\n",
        "            print('Validation acc after '+str(epoch_number+1)+' epochs = {:.{prec}f}'.format((100 * correct / total), prec=4))\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJHeXS2f9j9A",
        "colab_type": "text"
      },
      "source": [
        "### Grade UNFROZEN\n",
        "Let's see if there's a difference in accuracy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0YYPqci9j9B",
        "colab_type": "code",
        "outputId": "aec82af9-e950-487e-cdbb-3aaaccd92478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "def grade_mnist_unfrozen():\n",
        "    \n",
        "    # init a ft model\n",
        "    fine_tune_model = init_fine_tune_model()\n",
        "    \n",
        "    # run the transfer learning routine\n",
        "    UNFROZEN_fine_tune_mnist(pretrained_resnet18, fine_tune_model, mnist_train, mnist_val)\n",
        "    \n",
        "    # calculate test accuracy\n",
        "    test_accuracy = calculate_mnist_test_accuracy(pretrained_resnet18, fine_tune_model, mnist_test)\n",
        "    \n",
        "    # the real threshold will be released by Oct 11 \n",
        "    assert test_accuracy > 0.0, 'your accuracy is too low...'\n",
        "    \n",
        "    return test_accuracy\n",
        "    \n",
        "pretrained_resnet18 = models.resnet18(pretrained=True)\n",
        "pretrained_resnet18.fc = Identity()\n",
        "freeze_model(pretrained_resnet18)\n",
        "\n",
        "unfrozen_test_accuracy = grade_mnist_unfrozen()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation acc after 1 epochs = 62.2200\n",
            "Validation acc after 2 epochs = 68.2400\n",
            "Validation acc after 3 epochs = 70.6000\n",
            "Validation acc after 4 epochs = 72.0200\n",
            "Validation acc after 5 epochs = 72.8200\n",
            "Validation acc after 6 epochs = 73.7000\n",
            "Validation acc after 7 epochs = 74.1400\n",
            "Validation acc after 8 epochs = 74.6800\n",
            "Validation acc after 9 epochs = 74.9800\n",
            "Validation acc after 10 epochs = 75.2000\n",
            "Validation acc after 11 epochs = 97.8000\n",
            "Validation acc after 12 epochs = 98.3600\n",
            "Validation acc after 13 epochs = 98.4800\n",
            "Validation acc after 14 epochs = 98.6000\n",
            "Validation acc after 15 epochs = 98.8600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtbwNcLhgNUX",
        "colab_type": "code",
        "outputId": "0a68151a-596f-4b87-bbae-aa8af4aac044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "unfrozen_test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ6c7L0f9j9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert unfrozen_test_accuracy > frozen_test_accuracy, 'the unfrozen model should be better'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBBqwz_C9j9E",
        "colab_type": "text"
      },
      "source": [
        "--- \n",
        "## Question 2 (train a model on Wikitext-2)\n",
        "\n",
        "Here we'll apply what we just learned to NLP. In this section we'll make our own feature extractor and pretrain it on Wikitext-2.\n",
        "\n",
        "The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAYEa3BCZL3w",
        "colab_type": "text"
      },
      "source": [
        "##### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyg89bhoc5hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import RNNCell\n",
        "from torch.nn import RNNBase, RNN\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import Embedding\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5zwH2HOy6tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self, datasets, include_valid=False):\n",
        "        self.tokens = []\n",
        "        self.ids = {}\n",
        "        self.counts = {}\n",
        "        self.add_token('<bos>')\n",
        "        self.add_token('<eos>')\n",
        "        self.add_token('<pad>')\n",
        "        self.add_token('<unk>')\n",
        "        \n",
        "        for line in tqdm(datasets['train']):\n",
        "            for w in line:\n",
        "                self.add_token(w)\n",
        "                    \n",
        "        if include_valid is True:\n",
        "            for line in tqdm(datasets['valid']):\n",
        "                for w in line:\n",
        "                    self.add_token(w)\n",
        "                            \n",
        "    def add_token(self, w):\n",
        "        if w not in self.tokens:\n",
        "            self.tokens.append(w)\n",
        "            _w_id = len(self.tokens) - 1\n",
        "            self.ids[w] = _w_id\n",
        "            self.counts[w] = 1\n",
        "        else:\n",
        "            self.counts[w] += 1\n",
        "\n",
        "    def get_id(self, w):\n",
        "        return self.ids[w]\n",
        "    \n",
        "    def get_token(self, idx):\n",
        "        return self.tokens[idx]\n",
        "    \n",
        "    def decode_idx_seq(self, l):\n",
        "        return [self.tokens[i] for i in l]\n",
        "    \n",
        "    def encode_token_seq(self, l):\n",
        "        return [self.ids[i] if i in self.ids else self.ids['<unk>'] for i in l]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "\n",
        "def tokenize_dataset(datasets, dictionary, ngram_order=2):\n",
        "    tokenized_datasets = {}\n",
        "    for split, dataset in datasets.items():\n",
        "        _current_dictified = []\n",
        "        for l in tqdm(dataset):\n",
        "            l = ['<bos>']*(ngram_order-1) + l + ['<eos>']\n",
        "            encoded_l = dictionary.encode_token_seq(l)\n",
        "            _current_dictified.append(encoded_l)\n",
        "        tokenized_datasets[split] = _current_dictified\n",
        "        \n",
        "    return tokenized_datasets\n",
        "  \n",
        "class TensoredDataset(Dataset):\n",
        "    def __init__(self, list_of_lists_of_tokens):\n",
        "        self.input_tensors = []\n",
        "        self.target_tensors = []\n",
        "        \n",
        "        for sample in list_of_lists_of_tokens:\n",
        "            self.input_tensors.append(torch.tensor([sample[:-1]], dtype=torch.long))\n",
        "            self.target_tensors.append(torch.tensor([sample[1:]], dtype=torch.long))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # return a (input, target) tuple\n",
        "        return (self.input_tensors[idx], self.target_tensors[idx])\n",
        "\n",
        "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
        "    max_length = max([t.size(-1) for t in list_of_tensors])\n",
        "    padded_list = []\n",
        "    \n",
        "    for t in list_of_tensors:\n",
        "        padded_tensor = torch.cat([t, torch.tensor([[pad_token]*(max_length - t.size(-1))], dtype=torch.long)], dim = -1)\n",
        "        padded_list.append(padded_tensor)\n",
        "        \n",
        "    padded_tensor = torch.cat(padded_list, dim=0)\n",
        "    \n",
        "    return padded_tensor\n",
        "\n",
        "def pad_collate_fn(batch):\n",
        "    # batch is a list of sample tuples\n",
        "    input_list = [s[0] for s in batch]\n",
        "    target_list = [s[1] for s in batch]\n",
        "    \n",
        "    pad_token = wiki_dict.get_id('<pad>')\n",
        "    \n",
        "    input_tensor = pad_list_of_tensors(input_list, pad_token)\n",
        "    target_tensor = pad_list_of_tensors(target_list, pad_token)\n",
        "    \n",
        "    return input_tensor, target_tensor      \n",
        "  \n",
        "  \n",
        "def load_wikitext(filename='wikitext2-sentencized.json'):\n",
        "    if not os.path.exists(filename):\n",
        "        !wget \"https://nyu.box.com/shared/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\" -O $filename\n",
        "    \n",
        "    datasets = json.load(open(filename, 'r'))\n",
        "    for name in datasets:\n",
        "        datasets[name] = [x.split() for x in datasets[name]]\n",
        "    vocab = list(set([t for ts in datasets['train'] for t in ts]))      \n",
        "    print(\"Vocab size: %d\" % (len(vocab)))\n",
        "    return datasets, vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeTSTqmZX6u",
        "colab_type": "text"
      },
      "source": [
        "#### Part A\n",
        "In this section you need to generate the training, validation and test split. Feel free to use code from your previous lectures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37BLUWhMZb2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_wikitext_dataset():\n",
        "    \"\"\"\n",
        "    Fill in the details\n",
        "    \"\"\"\n",
        "    datasets, vocab=load_wikitext()\n",
        "    wiki_dict = pkl.load(open(\"wiki_dict.p\", \"rb\"))\n",
        "\n",
        "    wiki_tokenized_datasets = tokenize_dataset(datasets, wiki_dict)\n",
        "    \n",
        "    wiki_tensor_dataset = {}\n",
        "\n",
        "    for split, listoflists in wiki_tokenized_datasets.items():\n",
        "        wiki_tensor_dataset[split] = TensoredDataset(listoflists)\n",
        "\n",
        "    wiki_loaders = {}\n",
        "    batch_size = 32\n",
        "    for split, wiki_dataset in wiki_tensor_dataset.items():\n",
        "        wiki_loaders[split] = DataLoader(wiki_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)\n",
        "    wikitext_train=wiki_loaders['train']\n",
        "    wikitext_val=wiki_loaders['valid']\n",
        "    wikitext_test=wiki_loaders['test']\n",
        "    \n",
        "    return wikitext_train, wikitext_val, wikitext_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNCn8f7k9j9H",
        "colab_type": "text"
      },
      "source": [
        "#### Part B   \n",
        "Here we design our own feature extractor. In MNIST that was a resnet because we were dealing with images. Now we need to pick a model that can model sequences better. Design an RNN-based model here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYmPHFRO9j9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_feature_extractor():\n",
        "    options = {'embedding_dim': 128,\n",
        "           'hidden_size': 128,\n",
        "           'input_size': 128,\n",
        "           'num_embeddings': 33178,\n",
        "           'num_layers': 2,\n",
        "           'padding_idx': 2,\n",
        "           'rnn_dropout': 0.1}\n",
        "    class feature_extractor(nn.Module):\n",
        "      def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
        "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], batch_first=True)\n",
        "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
        "        \n",
        "      def forward(self, encoded_input_sequence):\n",
        "      \n",
        "        embeddings = self.lookup(encoded_input_sequence)\n",
        "        lstm_outputs = self.lstm(embeddings)\n",
        "        logits = self.projection(lstm_outputs[0])\n",
        "        \n",
        "        return logits\n",
        "    return feature_extractor(options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRitCPIY9j9J",
        "colab_type": "text"
      },
      "source": [
        "#### Part C\n",
        "Pretrain the feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYlLJvq9j9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_feature_extractor(feature_extractor, wikitext_train, wikitext_val):\n",
        "    # FILL IN THE DETAILS\n",
        "  current_device = torch.device('cuda')\n",
        "  model = feature_extractor.to(current_device)\n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=wiki_dict.get_id('<pad>'),reduction='sum')\n",
        "  model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "  optimizer = optim.Adam(model_parameters, lr=0.001)\n",
        "\n",
        "  for epoch_number in tqdm(range(8)):\n",
        "        avg_loss=0\n",
        "        # do train\n",
        "        model.train()\n",
        "        train_loss_cache = 0\n",
        "        train_non_pad_tokens_cache = 0\n",
        "        for i, (inp, target) in enumerate(wikitext_train):\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            train_loss_cache += loss.item()\n",
        "            non_pad_tokens = target.view(-1).ne(wiki_dict.get_id('<pad>')).sum().item()\n",
        "            train_non_pad_tokens_cache += non_pad_tokens\n",
        "            loss /= non_pad_tokens \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "\n",
        "        avg_loss = train_loss_cache / train_non_pad_tokens_cache\n",
        "        ppl = 2**(avg_loss/np.log(2))\n",
        "        if epoch_number == 7:\n",
        "            print('\\nAvg train perplexity = {:.{prec}f}'.format(ppl, prec=4))\n",
        "            \n",
        "            \n",
        "        valid_loss_cache = 0\n",
        "        valid_non_pad_tokens_cache = 0\n",
        "        #do valid\n",
        "        valid_losses = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (inp, target) in enumerate(wikitext_val):\n",
        "                inp = inp.to(current_device)\n",
        "                target = target.to(current_device)\n",
        "                logits = model(inp)\n",
        "\n",
        "                loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "                valid_loss_cache += loss.item()\n",
        "                non_pad_tokens = target.view(-1).ne(wiki_dict.get_id('<pad>')).sum().item()\n",
        "                valid_non_pad_tokens_cache += non_pad_tokens\n",
        "                \n",
        "            avg_val_loss = valid_loss_cache / valid_non_pad_tokens_cache\n",
        "            ppl_val = 2**(avg_val_loss/np.log(2))\n",
        "            if epoch_number == 7:\n",
        "                print('\\nValidation Perplexity = {:.{prec}f}'.format(ppl_val, prec=4))\n",
        "                print()\n",
        "\n",
        "  torch.save(model.state_dict(), \"LSTM_feature_extractor.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g1F3FFM9j9L",
        "colab_type": "text"
      },
      "source": [
        "#### Part D\n",
        "Calculate the test perplexity on wikitext2. Feel free to recycle code from previous assignments from this class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvIiGfMq9j9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_wiki2_test_perplexity(feature_extractor, wikitext_test):\n",
        "    \n",
        "    # FILL IN DETAILS\n",
        "    current_device = torch.device('cuda')\n",
        "    model=feature_extractor.to(current_device)\n",
        "    model.load_state_dict(torch.load('LSTM_feature_extractor.ckpt'))\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=wiki_dict.get_id('<pad>'),reduction='sum')\n",
        "    model.eval()\n",
        "    test_loss_cache = 0\n",
        "    test_non_pad_tokens_cache = 0\n",
        "    \n",
        "    model.eval()\n",
        "    for i, (inp, target) in enumerate(wikitext_test):\n",
        "        inp = inp.to(current_device)\n",
        "        target = target.to(current_device)\n",
        "        logits = model(inp)\n",
        "\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "        test_loss_cache += loss.item()\n",
        "        non_pad_tokens = target.view(-1).ne(wiki_dict.get_id('<pad>')).sum().item()\n",
        "        test_non_pad_tokens_cache += non_pad_tokens\n",
        "\n",
        "    avg_test_loss = test_loss_cache / test_non_pad_tokens_cache\n",
        "    test_ppl = 2**(avg_test_loss/np.log(2))\n",
        "    return test_ppl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xetjgGsP9j9O",
        "colab_type": "text"
      },
      "source": [
        "#### Let's grade your results!\n",
        "(don't touch this part)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El_FxBhA9j9O",
        "colab_type": "code",
        "outputId": "c815daf6-a7c6-402a-f8ed-8d43aee3e0b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "def grade_wikitext2():\n",
        "    # load data\n",
        "    wikitext_train, wikitext_val, wikitext_test = init_wikitext_dataset()\n",
        "\n",
        "    # load feature extractor\n",
        "    feature_extractor = init_feature_extractor()\n",
        "\n",
        "    # pretrain using the feature extractor\n",
        "    fit_feature_extractor(feature_extractor, wikitext_train, wikitext_val)\n",
        "\n",
        "    # check test accuracy\n",
        "    test_ppl = calculate_wiki2_test_perplexity(feature_extractor, wikitext_test)\n",
        "\n",
        "    # the real threshold will be released by Oct 11 \n",
        "    assert test_ppl < 200, 'ummm... your perplexity is too high...'\n",
        "    \n",
        "grade_wikitext2()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 13051/78274 [00:00<00:00, 130507.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 33175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78274/78274 [00:00<00:00, 127621.12it/s]\n",
            "100%|██████████| 8464/8464 [00:00<00:00, 131296.93it/s]\n",
            "100%|██████████| 9708/9708 [00:00<00:00, 132846.68it/s]\n",
            " 88%|████████▊ | 7/8 [19:40<02:48, 168.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Avg train perplexity = 109.5618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 8/8 [22:28<00:00, 168.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Perplexity = 193.8261\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go_CynLE3w7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0362eec7-de34-4a26-d1b6-1120a8e44a1d"
      },
      "source": [
        "!md5sum LSTM_feature_extractor.ckpt"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fa99e1bc2633f1d302aab1c1d9425727  LSTM_feature_extractor.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4qL74U29j9Q",
        "colab_type": "text"
      },
      "source": [
        "---   \n",
        "## Question 3 (fine-tune on MNLI)\n",
        "In this question you will use your feature_extractor from question 2\n",
        "to fine-tune on MNLI.\n",
        "\n",
        "(From the website):\n",
        "The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information. The corpus is modeled on the SNLI corpus, but differs in that covers a range of genres of spoken and written text, and supports a distinctive cross-genre generalization evaluation. The corpus served as the basis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen.\n",
        "\n",
        "MNLI has 3 genres (3 classes).\n",
        "The goal of this question is to maximize the test accuracy in MNLI. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIZnJA_B9j9R",
        "colab_type": "text"
      },
      "source": [
        "### Part A\n",
        "In this section you need to generate the training, validation and test split. Feel free to use code from your previous lectures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIEyqKWGj-uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "import pickle as pkl\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import  MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from torch import nn\n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKdw6H1Z9j9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mnli_dataset():\n",
        "    y_label_map = {'contradiction':0,'neutral':1,'entailment':2}\n",
        "\n",
        "    def get_string_tokenized_data(data):\n",
        "\n",
        "        tokenized_data_x = [];\n",
        "        y_labels = []\n",
        "        all_tokens = [];\n",
        "\n",
        "        for i,x in enumerate(data):\n",
        "            label = x[2]\n",
        "            if label == 'nan':\n",
        "                continue\n",
        "\n",
        "            label = y_label_map[label]\n",
        "            y_labels.append(label)\n",
        "\n",
        "            dp = [x[0].split(), x[1].split()]\n",
        "            tokenized_data_x.append(dp)\n",
        "            all_tokens += (dp[0] + dp[1])\n",
        "\n",
        "\n",
        "        return all_tokens, tokenized_data_x, y_labels\n",
        "\n",
        "    # LOAD VAL\n",
        "\n",
        "    val_df = pd.read_csv('mnli_val.tsv', sep=\"\\t\")\n",
        "\n",
        "    val_df  = np.array(val_df)\n",
        "    val_genre_list = val_df[:, 3]\n",
        "\n",
        "    _, val_data_x, val_data_y = get_string_tokenized_data(val_df)\n",
        "    del val_df\n",
        "\n",
        "    train_df = pd.read_csv('mnli_train.tsv', sep=\"\\t\")\n",
        "\n",
        "    train_df  = np.array(train_df)\n",
        "    train_genre_list = train_df[:, 3]\n",
        "\n",
        "    _, train_data_x, train_data_y = get_string_tokenized_data(train_df)\n",
        "    del train_df\n",
        "\n",
        "\n",
        "    mnli_raw_datasets = {'train': train_data_x, 'val': val_data_x}\n",
        "    mnli_tokenized_datasets = tokenize_mnli_dataset(mnli_raw_datasets, wiki_dict)\n",
        "\n",
        "    train_data_indices = mnli_tokenized_datasets['train']\n",
        "    val_data_indices = mnli_tokenized_datasets['val']\n",
        "\n",
        "\n",
        "\n",
        "    del mnli_tokenized_datasets\n",
        "\n",
        "    unique_genre = list(set(val_genre_list));\n",
        "    nb_classes = len(y_label_map)\n",
        "\n",
        "    MAX_SENTENCE_LENGTH = 200\n",
        "\n",
        "    class MNLIDataset(Dataset):\n",
        "        def __init__(self, data_x, target_list):\n",
        "            self.data_x = data_x;\n",
        "            self.target_list = target_list\n",
        "\n",
        "            assert(len(data_x) == len(target_list))\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.target_list)\n",
        "\n",
        "        def __getitem__(self, key):\n",
        "\n",
        "            prem_token_idx = self.data_x[key][0][:MAX_SENTENCE_LENGTH]\n",
        "            hyp_token_idx = self.data_x[key][1][:MAX_SENTENCE_LENGTH]\n",
        "            label = self.target_list[key]\n",
        "            return [prem_token_idx, hyp_token_idx, label]\n",
        "\n",
        "\n",
        "    def encode_collate_func(batch):\n",
        "        \"\"\"\n",
        "        Customized function for DataLoader that dynamically pads the batch so that all\n",
        "        data have the same length\n",
        "        \"\"\"\n",
        "        prem_data_list = []\n",
        "        hyp_data_list = []\n",
        "        label_list = []\n",
        "        length_list = []\n",
        "        # print(\"collate batch: \", batch[0][0])\n",
        "        # batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
        "        for datum in batch:\n",
        "            label_list.append(datum[2])\n",
        "        # padding\n",
        "        for datum in batch:\n",
        "            prem_padded_vec = np.pad(np.array(datum[0]),\n",
        "                                     pad_width=((0, MAX_SENTENCE_LENGTH - len(datum[0]))),\n",
        "                                     mode=\"constant\", constant_values=wiki_dict.get_id('<pad>'))\n",
        "            hyp_padded_vec = np.pad(np.array(datum[1]),\n",
        "                                    pad_width=((0, MAX_SENTENCE_LENGTH - len(datum[1]))),\n",
        "                                    mode=\"constant\", constant_values=wiki_dict.get_id('<pad>'))\n",
        "            prem_data_list.append(prem_padded_vec)\n",
        "            hyp_data_list.append(hyp_padded_vec)\n",
        "        return [torch.from_numpy((np.array(prem_data_list))), torch.from_numpy(np.array(hyp_data_list)),\n",
        "                torch.LongTensor(label_list)]\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    nb_train_samples = int(0.95 * len(train_data_indices))\n",
        "    nb_val_samples = len(train_data_indices) - nb_train_samples\n",
        "\n",
        "    # train/val split\n",
        "    train_val_dataset = MNLIDataset(train_data_indices, train_data_y)\n",
        "    train_dataset, val_dataset = random_split(train_val_dataset, [nb_train_samples, nb_val_samples])\n",
        "\n",
        "    # train loader\n",
        "    train_mnli_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               collate_fn=encode_collate_func,\n",
        "                                               shuffle=True)\n",
        "\n",
        "    # val loader\n",
        "    val_mnli_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               collate_fn=encode_collate_func,\n",
        "                                               shuffle=True)\n",
        "\n",
        "    # test loader\n",
        "    test_dataset = MNLIDataset(val_data_indices, val_data_y)\n",
        "    test_mnli_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               collate_fn=encode_collate_func,\n",
        "                                               shuffle=True)\n",
        "\n",
        "    return train_mnli_loader, val_mnli_loader, test_mnli_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ewZ87n9j9Z",
        "colab_type": "text"
      },
      "source": [
        "### Part B\n",
        "Here we again design a model for finetuning. Use the output of your feature-extractor as the input to this model. This should be a powerful classifier (up to you)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmxUpruRfl8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_feature_extractor():\n",
        "    options = {'embedding_dim': 128,\n",
        "           'hidden_size': 128,\n",
        "           'input_size': 128,\n",
        "           'num_embeddings': 33178,\n",
        "           'num_layers': 2,\n",
        "           'padding_idx': 2,\n",
        "           'rnn_dropout': 0.1}\n",
        "    class feature_extractor(nn.Module):\n",
        "      def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
        "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], batch_first=True)\n",
        "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
        "        \n",
        "      def forward(self, encoded_input_sequence):\n",
        "      \n",
        "        embeddings = self.lookup(encoded_input_sequence)\n",
        "        lstm_outputs = self.lstm(embeddings)\n",
        "        logits = self.projection(lstm_outputs[0])\n",
        "        \n",
        "        return logits\n",
        "    return feature_extractor(options)\n",
        "device = torch.device('cuda')\n",
        "feature_extractor_model = init_feature_extractor().to(device)\n",
        "feature_extractor_model.load_state_dict(torch.load('LSTM_feature_extractor.ckpt'))\n",
        "feature_extractor_model.projection = Identity()\n",
        "freeze_model(feature_extractor_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srTd6kDh9j9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_fine_tune_model():\n",
        "  class fine_tune_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.s= nn.Sequential(nn.Linear(2*128,256), nn.ReLU(), nn.Linear(256,512), nn.ReLU(), nn.Dropout(0.2), nn.Linear(512, 3))   \n",
        "    def forward(self, data):\n",
        "        logits=self.s(data)\n",
        "        return logits\n",
        "  return fine_tune_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsZC7Bff9j9b",
        "colab_type": "text"
      },
      "source": [
        "### Part C\n",
        "Use the feature_extractor and your fine_tune_model to fine_tune MNLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gikd0PJm9j9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "def fine_tune_mnli(feature_extractor, fine_tune_model, mnli_train, mnli_val):\n",
        "    # YOUR CODE HERE\n",
        "    current_device = torch.device(\"cuda:0\")\n",
        "    freeze_model(feature_extractor)\n",
        "    model = nn.Sequential(feature_extractor.lookup, fine_tune_model)\n",
        "    model = model.to(current_device)\n",
        "  \n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],lr=2e-5)\n",
        "\n",
        "    \n",
        "    for epoch in tqdm(range(10)):\n",
        "      if epoch>=5:\n",
        "        unfreeze_model(model)\n",
        "        optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],lr=2e-5)\n",
        "      model.train()\n",
        "      \n",
        "      for i, (inp1,inp2, target) in enumerate(mnli_train):\n",
        "          optimizer.zero_grad()\n",
        "          inp1 = inp1.to(current_device)\n",
        "          inp2 = inp2.to(current_device)\n",
        "          target = target.to(current_device)\n",
        "          feature1 = model[0](inp1)\n",
        "          feature2 = model[0](inp2)\n",
        "          feature1 = torch.sum(feature1,dim=1)\n",
        "          feature2 = torch.sum(feature2,dim=1)\n",
        "          inp = torch.cat([feature1, feature2], dim=1)\n",
        "          logits = model[1](inp)\n",
        "          loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "          \n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "      model.eval()\n",
        "      total=0\n",
        "      correct=0\n",
        "      with torch.no_grad():\n",
        "          for i, (inp1,inp2, target) in enumerate(mnli_val):\n",
        "              inp1 = inp1.to(current_device)\n",
        "              inp2 = inp2.to(current_device)\n",
        "              target = target.to(current_device)\n",
        "              feature1 = model[0](inp1)\n",
        "              feature2 = model[0](inp2)\n",
        "              feature1 = torch.sum(feature1,dim=1)\n",
        "              feature2 = torch.sum(feature2,dim=1)\n",
        "              inp = torch.cat([feature1, feature2], dim=1)\n",
        "              logits = model[1](inp)\n",
        "              \n",
        "              outputs = F.softmax(logits,dim=1)\n",
        "              predicted = outputs.max(1, keepdim=True)[1]\n",
        "              total += target.size(0)\n",
        "              correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
        "\n",
        "          print('Validation acc = {:.{prec}f}'.format((100 * correct / total), prec=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRv_NhG39j9d",
        "colab_type": "text"
      },
      "source": [
        "### Part D\n",
        "Evaluate the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJHhhFxq9j9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_mnli_test_accuracy(feature_extractor, fine_tune_model, mnli_test):\n",
        "    \n",
        "    current_device = torch.device(\"cuda:0\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model = nn.Sequential(feature_extractor.lookup, fine_tune_model)\n",
        "    model.eval()    \n",
        "    for inp1, inp2, target in mnli_test:\n",
        "        inp1 = inp1.to(current_device)\n",
        "        inp2 = inp2.to(current_device)\n",
        "        target = target.to(current_device)\n",
        "        feature1 = model[0](inp1)\n",
        "        feature2 = model[0](inp2)\n",
        "        feature1 = torch.sum(feature1,dim=1)\n",
        "        feature2 = torch.sum(feature2,dim=1)\n",
        "        inp = torch.cat([feature1, feature2], dim=1)\n",
        "        logits = model[1](inp)\n",
        "\n",
        "        outputs = F.softmax(logits,dim=1)\n",
        "        predicted = outputs.max(1, keepdim=True)[1]\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
        "    \n",
        "    return 100*correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9u0oG5F9j9f",
        "colab_type": "text"
      },
      "source": [
        "### Let's grade your results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9R6ngIl9j9g",
        "colab_type": "code",
        "outputId": "96d52f0f-7ad3-4e98-dded-78fb47d9d21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "def grade_mnli():\n",
        "    # load data\n",
        "    mnli_train, mnli_val, mnli_test = init_mnli_dataset()\n",
        "\n",
        "    # no need to load feature extractor because it is fine-tuned\n",
        "    feature_extractor = feature_extractor_model\n",
        "\n",
        "    # init the fine_tune model\n",
        "    fine_tune_model = init_fine_tune_model()\n",
        "    \n",
        "    # finetune\n",
        "    fine_tune_mnli(feature_extractor, fine_tune_model, mnli_train, mnli_val)\n",
        "\n",
        "    # check test accuracy\n",
        "    test_accuracy = calculate_mnli_test_accuracy(feature_extractor, fine_tune_model, mnli_test)\n",
        "\n",
        "    # the real threshold will be released by Oct 11 \n",
        "    assert test_accuracy > 0.00, 'ummm... your accuracy is too low...'\n",
        "    \n",
        "    return test_accuracy\n",
        "    \n",
        "test_accuracy = grade_mnli()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [00:00<00:00, 49537.28it/s]\n",
            "100%|██████████| 5000/5000 [00:00<00:00, 78110.58it/s]\n",
            " 10%|█         | 1/10 [00:03<00:30,  3.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 38.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:06<00:27,  3.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 38.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:09<00:23,  3.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 37.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:13<00:19,  3.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 38.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [00:16<00:16,  3.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 39.3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:20<00:14,  3.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 40.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:24<00:11,  3.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 40.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [00:28<00:07,  3.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 41.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [00:32<00:03,  3.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 42.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [00:36<00:00,  3.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 41.7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3ujIgbYlcZS",
        "colab_type": "code",
        "outputId": "075031df-31a0-42f9-fbed-f7a53793f296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsLuJaFM9j9h",
        "colab_type": "text"
      },
      "source": [
        "---  \n",
        "## Question 4 (BERT)\n",
        "\n",
        "A major direction in research came from a model called BERT, released last year.  \n",
        "\n",
        "In this question you'll use BERT as your feature_extractor instead of the model you\n",
        "designed yourself.\n",
        "\n",
        "To get BERT, head on over to (https://github.com/huggingface/transformers) and load your BERT model here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxrE8uxMaIue",
        "colab_type": "text"
      },
      "source": [
        "#### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl2D6FKb9j9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import argparse\n",
        "import tempfile\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from tqdm import tqdm, trange\n",
        "import pickle as pkl\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split, RandomSampler\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import  MNIST\n",
        "from transformers.data.processors.glue import MnliProcessor\n",
        "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
        "from transformers import (\n",
        "    BertModel,\n",
        "    BertTokenizer\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFAYhgaM5OVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "        \n",
        "def unfreeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiBuQNEoLuPk",
        "colab_type": "code",
        "outputId": "fcb66088-47a8-45a0-965a-09ce63e41449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "TASKS = [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"SNLI\", \"QNLI\", \"RTE\", \"WNLI\", \"diagnostic\"]\n",
        "TASK2PATH = {\n",
        "    \"CoLA\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FCoLA.zip?alt=media&token=46d5e637-3411-4188-bc44-5809b5bfb5f4\",  # noqa\n",
        "    \"SST\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\",  # noqa\n",
        "    \"MRPC\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc\",  # noqa\n",
        "    \"QQP\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQQP-clean.zip?alt=media&token=11a647cb-ecd3-49c9-9d31-79f8ca8fe277\",  # noqa\n",
        "    \"STS\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSTS-B.zip?alt=media&token=bddb94a7-8706-4e0d-a694-1109e12273b5\",  # noqa\n",
        "    \"MNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FMNLI.zip?alt=media&token=50329ea1-e339-40e2-809c-10c40afff3ce\",  # noqa\n",
        "    \"SNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSNLI.zip?alt=media&token=4afcfbb2-ff0c-4b2d-a09a-dbf07926f4df\",  # noqa\n",
        "    \"QNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FQNLIv2.zip?alt=media&token=6fdcf570-0fc5-4631-8456-9505272d1601\",  # noqa\n",
        "    \"RTE\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FRTE.zip?alt=media&token=5efa7e85-a0bb-4f19-8ea2-9e1840f077fb\",  # noqa\n",
        "    \"WNLI\": \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FWNLI.zip?alt=media&token=068ad0a0-ded7-4bd7-99a5-5e00222e0faf\",  # noqa\n",
        "    \"diagnostic\": [\n",
        "        \"https://storage.googleapis.com/mtl-sentence-representations.appspot.com/tsvsWithoutLabels%2FAX.tsv?GoogleAccessId=firebase-adminsdk-0khhl@mtl-sentence-representations.iam.gserviceaccount.com&Expires=2498860800&Signature=DuQ2CSPt2Yfre0C%2BiISrVYrIFaZH1Lc7hBVZDD4ZyR7fZYOMNOUGpi8QxBmTNOrNPjR3z1cggo7WXFfrgECP6FBJSsURv8Ybrue8Ypt%2FTPxbuJ0Xc2FhDi%2BarnecCBFO77RSbfuz%2Bs95hRrYhTnByqu3U%2FYZPaj3tZt5QdfpH2IUROY8LiBXoXS46LE%2FgOQc%2FKN%2BA9SoscRDYsnxHfG0IjXGwHN%2Bf88q6hOmAxeNPx6moDulUF6XMUAaXCSFU%2BnRO2RDL9CapWxj%2BDl7syNyHhB7987hZ80B%2FwFkQ3MEs8auvt5XW1%2Bd4aCU7ytgM69r8JDCwibfhZxpaa4gd50QXQ%3D%3D\",  # noqa\n",
        "        \"https://www.dropbox.com/s/ju7d95ifb072q9f/diagnostic-full.tsv?dl=1\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "MRPC_TRAIN = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\"\n",
        "MRPC_TEST = \"https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt\"\n",
        "\n",
        "\n",
        "def download_and_extract(task, data_dir):\n",
        "    print(\"Downloading and extracting %s...\" % task)\n",
        "    data_file = \"%s.zip\" % task\n",
        "    urllib.request.urlretrieve(TASK2PATH[task], data_file)\n",
        "    with zipfile.ZipFile(data_file) as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(data_file)\n",
        "    print(\"\\tCompleted!\")\n",
        "\n",
        "download_and_extract('MNLI', '.')\n",
        "processor = MnliProcessor()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting MNLI...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZULRBz59j9j",
        "colab_type": "text"
      },
      "source": [
        "### Part A (init BERT)\n",
        "In this section you need to create an instance of BERT and return if from the function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYylV9lTOgZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_bert():\n",
        "    bert = BertModel.from_pretrained('bert-base-cased', output_attentions=True)\n",
        "    return bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y26gWZrDOM5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_mnli_dataset(train=True):\n",
        "  # ----------------------\n",
        "  # TRAIN/VAL DATALOADERS\n",
        "  # ----------------------\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "    if train == True:\n",
        "        train = processor.get_train_examples('MNLI')\n",
        "        features = convert_examples_to_features(train,tokenizer,label_list=['contradiction','neutral','entailment'],\n",
        "                            max_length=128,output_mode='classification',\n",
        "                            pad_on_left=False,pad_token=tokenizer.pad_token_id,pad_token_segment_id=0)\n",
        "        train_dataset = TensorDataset(torch.tensor([f.input_ids for f in features], dtype=torch.long), \n",
        "                                    torch.tensor([f.attention_mask for f in features], dtype=torch.long), \n",
        "                                    torch.tensor([f.token_type_ids for f in features], dtype=torch.long), \n",
        "                                    torch.tensor([f.label for f in features], dtype=torch.long))\n",
        "\n",
        "        nb_train_samples = int(0.75 * len(train_dataset))\n",
        "        nb_val_samples = len(train_dataset) - nb_train_samples\n",
        "\n",
        "        bert_mnli_train_dataset, bert_mnli_val_dataset = random_split(train_dataset, [nb_train_samples, nb_val_samples])\n",
        "\n",
        "      # train loader\n",
        "        train_sampler = RandomSampler(bert_mnli_train_dataset)\n",
        "        bert_mnli_train_dataloader = DataLoader(bert_mnli_train_dataset, sampler=train_sampler, batch_size=32)\n",
        "\n",
        "      # val loader\n",
        "        val_sampler = RandomSampler(bert_mnli_val_dataset)\n",
        "        bert_mnli_val_dataloader = DataLoader(bert_mnli_val_dataset, sampler=val_sampler, batch_size=32)\n",
        "\n",
        "  # ----------------------\n",
        "  # TEST DATALOADERS\n",
        "  # ----------------------\n",
        "    dev = processor.get_dev_examples('MNLI')\n",
        "    features = convert_examples_to_features(dev,tokenizer,label_list=['contradiction','neutral','entailment'],\n",
        "                         max_length=128,output_mode='classification',\n",
        "                         pad_on_left=False,pad_token=tokenizer.pad_token_id,pad_token_segment_id=0)\n",
        "\n",
        "    bert_mnli_test_dataset = TensorDataset(torch.tensor([f.input_ids for f in features], dtype=torch.long), \n",
        "                                torch.tensor([f.attention_mask for f in features], dtype=torch.long), \n",
        "                                torch.tensor([f.token_type_ids for f in features], dtype=torch.long), \n",
        "                                torch.tensor([f.label for f in features], dtype=torch.long))\n",
        "\n",
        "  # test dataset\n",
        "    test_sampler = RandomSampler(bert_mnli_test_dataset)\n",
        "    bert_mnli_test_dataloader = DataLoader(bert_mnli_test_dataset, sampler=test_sampler, batch_size=32)\n",
        "  \n",
        "    return bert_mnli_train_dataloader, bert_mnli_val_dataloader, bert_mnli_test_dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YteosVnoPozJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_finetune_model():\n",
        "    class fine_tune_model(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.s= nn.Sequential(nn.Linear(768,512), nn.ReLU(), \n",
        "                                  nn.Linear(512,128), nn.ReLU(), nn.Dropout(0.1), nn.Linear(128,3))   \n",
        "        def forward(self, data):\n",
        "            logits=self.s(data)\n",
        "            return logits\n",
        "    return fine_tune_model()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X22LqDrn9j9l",
        "colab_type": "text"
      },
      "source": [
        "### Part B (fine-tune with BERT)\n",
        "\n",
        "Use BERT as your feature extractor to finetune MNLI. Use a new finetune model (reset weights)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uvbg2h_9j9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fine_tune_mnli_BERT(BERT_feature_extractor, fine_tune_model, mnli_train, mnli_val):\n",
        "    # YOUR CODE HERE\n",
        "    current_device = torch.device(\"cuda\")\n",
        "    model = nn.Sequential(BERT_feature_extractor, fine_tune_model)\n",
        "    model = model.to(current_device)\n",
        "    unfreeze_model(model)\n",
        "    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],lr=2e-5)\n",
        "    criterion = torch.nn.CrossEntropyLoss(ignore_index=-1).to(current_device)\n",
        "\n",
        "    model.train()\n",
        "    for inp,mask,token,target in tqdm(mnli_train):\n",
        "        inp = inp.to(current_device)\n",
        "        mask = mask.to(current_device)\n",
        "        token = token.to(current_device)\n",
        "        target = target.to(current_device) \n",
        "        h, _, attn = model[0](input_ids=inp, \n",
        "                     attention_mask=mask, \n",
        "                     token_type_ids=token)\n",
        "        h = h[:,0]\n",
        "        logits = model[1](h)\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "    torch.save(model.state_dict(), \"BERT_finetune.ckpt\")\n",
        "\n",
        "    model.eval()\n",
        "    total=0\n",
        "    correct=0\n",
        "    with torch.no_grad():\n",
        "        for inp,mask,token,target in mnli_val:\n",
        "            inp = inp.to(current_device)\n",
        "            mask = mask.to(current_device)\n",
        "            token = token.to(current_device)\n",
        "            target = target.to(current_device) \n",
        "            h, _, attn = model[0](input_ids=inp,attention_mask=mask, \n",
        "                         token_type_ids=token)\n",
        "            h = h[:,0]\n",
        "            logits = model[1](h)\n",
        "            outputs = F.softmax(logits,dim=1)\n",
        "            predicted = outputs.max(1, keepdim=True)[1]\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target.view_as(predicted)).sum().item()\n",
        "    print('Validation acc = {:.{prec}f}'.format((100 * correct / total), prec=4))\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL4uy2709j9n",
        "colab_type": "text"
      },
      "source": [
        "### Part C(Evaluate how well we did)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BALil7_9j9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_mnli_test_accuracy_BERT(feature_extractor, fine_tune_model, mnli_test):   \n",
        "    current_device = torch.device(\"cuda:0\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model = nn.Sequential(feature_extractor, fine_tune_model)\n",
        "    model = model.to(current_device)\n",
        "    model.eval()    \n",
        "    for inp,mask,token,target in mnli_test:\n",
        "        inp = inp.to(current_device)\n",
        "        mask = mask.to(current_device)\n",
        "        token = token.to(current_device)\n",
        "        target = target.to(current_device) \n",
        "        h, _, attn = model[0](input_ids=inp, attention_mask=mask, \n",
        "                     token_type_ids=token)\n",
        "        h = h[:,0]\n",
        "        logits = model[1](h)\n",
        "        outputs = F.softmax(logits,dim=1)\n",
        "        predicted = outputs.max(1, keepdim=True)[1]\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.view_as(predicted)).sum().item()  \n",
        "    return 100*correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYMa4xMC9j9q",
        "colab_type": "text"
      },
      "source": [
        "### Let's grade your BERT results!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAiqEIMc9j9r",
        "colab_type": "code",
        "outputId": "76657ae8-04fe-43dc-da4a-dd8d92419ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "def grade_mnli_BERT():\n",
        "    BERT_feature_extractor = init_bert()\n",
        "    \n",
        "    # load data\n",
        "    mnli_train, mnli_val, mnli_test = init_mnli_dataset()\n",
        "\n",
        "    # init the fine_tune model\n",
        "    fine_tune_model = init_finetune_model()\n",
        "    \n",
        "    # finetune\n",
        "    fine_tune_mnli_BERT(BERT_feature_extractor, fine_tune_model, mnli_train, mnli_val)\n",
        "\n",
        "    # check test accuracy\n",
        "    test_accuracy = calculate_mnli_test_accuracy_BERT(BERT_feature_extractor, fine_tune_model, mnli_test)\n",
        "    \n",
        "    # the real threshold will be released by Oct 11 \n",
        "    assert test_accuracy > 0.8, 'ummm... your accuracy is too low...'\n",
        "    \n",
        "    return test_accuracy\n",
        "    \n",
        "grade_mnli_BERT() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 239390.44B/s]\n",
            "100%|██████████| 435779157/435779157 [00:07<00:00, 55074928.32B/s]\n",
            "100%|██████████| 213450/213450 [00:00<00:00, 2530917.75B/s]\n",
            "100%|██████████| 9204/9204 [3:26:18<00:00,  1.33s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation acc = 82.1555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.26184411614875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_cg4YkTa6F1",
        "colab_type": "code",
        "outputId": "66edf72e-f840-4153-897e-c5b9509a0728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "model = nn.Sequential(init_bert(), init_finetune_model())\n",
        "model.load_state_dict(torch.load('BERT_finetune.ckpt'))\n",
        "mnli_train, mnli_val, mnli_test = init_mnli_dataset()\n",
        "test_accuracy = calculate_mnli_test_accuracy_BERT(model[0], model[1], mnli_test)\n",
        "print('Test Accuracy is: {}'.format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 199941.69B/s]\n",
            "100%|██████████| 435779157/435779157 [00:07<00:00, 55102206.01B/s]\n",
            "100%|██████████| 213450/213450 [00:00<00:00, 5479839.08B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy is: 82.26184411614875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgqjcF_-34A-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73cfd7b8-f0db-4914-867f-820914fb4014"
      },
      "source": [
        "!md5sum BERT_finetune.ckpt"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68b209b1ccaa6ace256983d4e83580c9  BERT_finetune.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}